{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef6612-e7ee-428a-a236-5765ff5ff9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, subprocess, pickle, tifffile, copy\n",
    "import numpy as np\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# sys.path.insert(0, '/asap3/petra3/gpfs/common/p21.2/scripts/')\n",
    "sys.path.insert(0, '/home/sjoehann/')\n",
    "import pyTSXRD\n",
    "from pyTSXRD.angles_and_ranges import merge_overlaps\n",
    "from pyTSXRD.DataAnalysis import merge_DATA_list, plot_sinogram, compute_sinogram\n",
    "import experiment_settings\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.spatial.distance import cdist\n",
    "from orix import plot, sampling\n",
    "from orix.crystal_map import Phase\n",
    "from orix.quaternion import Orientation, symmetry\n",
    "from orix.vector import Vector3d\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from hexrd import imageseries\n",
    "from hexrd.imageseries.omega import OmegaWedges\n",
    "from numpy import float32\n",
    "import fabio\n",
    "\n",
    "single_separator = \"--------------------------------------------------------------\"\n",
    "double_separator = \"==============================================================\"\n",
    "\n",
    "### SETTING GLOBAL VARIABLES - DIRECTORY ROOT AND MATERIAL:\n",
    "# path_gen = '/asap3/petra3/gpfs/p21.2/2022/data/11013744/'\n",
    "path_gen = '/asap3/petra3/gpfs/p21.2/2023/data/11016686/' #raw/polyAu04/038_y1_0.0000/Varex_4/' 022_y1_-1.6000.fio\n",
    "materials_table = {'Au'  : {'name': 'Au'  , 'spacegroup': 225, 'symmetry':'F', 'unitcell': [4.0782, 4.0782,  4.0782, 90., 90.,  90.]},\n",
    "                   'CeO2': {'name': 'CeO2', 'spacegroup': 225, 'symmetry':'F', 'unitcell': [5.4115, 5.4115,  5.4115, 90., 90.,  90.]},\n",
    "                   'Cu'  : {'name': 'Cu'  , 'spacegroup': 225, 'symmetry':'F', 'unitcell': [3.5942, 3.5942,  3.5942, 90., 90.,  90.]},\n",
    "                   'LaB6': {'name': 'LaB6', 'spacegroup': 221, 'symmetry':'P', 'unitcell': [4.1568, 4.1568,  4.1568, 90., 90.,  90.]},\n",
    "                   'MgCa': {'name': 'MgCa', 'spacegroup': 194, 'symmetry':'P', 'unitcell': [3.1980, 3.1980,  5.1900, 90., 90., 120.]},\n",
    "                   'Nb'  : {'name': 'Nb'  , 'spacegroup': 229, 'symmetry':'I', 'unitcell': [3.3042, 3.3042,  3.3042, 90., 90.,  90.]},\n",
    "                   'Ni'  : {'name': 'Ni'  , 'spacegroup': 225, 'symmetry':'F', 'unitcell': [3.5100, 3.5100,  3.5100, 90., 90.,  90.]},\n",
    "                   'Pd'  : {'name': 'Pd'  , 'spacegroup': 225, 'symmetry':'F', 'unitcell': [3.8907, 3.8907,  3.8907, 90., 90.,  90.]},\n",
    "                   'Ruby': {'name': 'Ruby', 'spacegroup': 167, 'symmetry':'R', 'unitcell': [4.7608, 4.7608, 12.9957, 90., 90., 120.]},\n",
    "                   'Ti'  : {'name': 'Ti'  , 'spacegroup': 194, 'symmetry':'P', 'unitcell': [2.9505, 2.9505,  4.6826, 90., 90., 120.]}}\n",
    "\n",
    "material = materials_table['Pd']\n",
    "\n",
    "### SETTING THE SWEEPSCANS PARAMETERS, AND OTHER OBJECTS:\n",
    "def set_SweepProcessor(path_gen, i_load, i_slow, i_fast, det_num, material):\n",
    "    default_xyz = [0,0,0]\n",
    "    y_points = np.linspace(-3.6, 3.6, 73) # y-motor positions if needed\n",
    "    meta_key = path_gen + f'raw/polyPd05/{i_fast:03d}_y1_{y_points[i_fast]:.4f}.fio' # metadata of the sweep    \n",
    "    S = experiment_settings.set_p212_sweep(path_gen, i_slow, i_fast, det_num, default_xyz, meta_key) # this function usually don't need modifications\n",
    "    if S.sweep['stem'][-1] != '_': S.sweep['stem'] += '_' # correct for possible mismatch between file stems in the sweep command and actual file names\n",
    "    S.processing['options'] = None # ('flip', 'r270') # detector flips if needed to be applied before those in geometry file\n",
    "    S.directory = S.directory.replace('/polyPd05/', '/hannasjo/polyPd05/') # if needed to modify the output directory (ie when the default one must not be overwritten)\n",
    "    S.geometry.load_par(directory = path_gen + 'processed/hannasjo/', par_file = f'Pd_pyFAI_calib.par')\n",
    "#     S.geometry.load_yml(directory = path_gen + 'processed/Anatoly/', yml_file = f'Au_calib.yml')\n",
    "    S.geometry.set_attr('material', material)\n",
    "    S.geometry.spline_file = None # Either None for perfect detector, or path to spline file\n",
    "    S.geometry.set_attr('wavelength' , 12.39842/38)\n",
    "    return S\n",
    "\n",
    "#TOLERANCES USED IN MORE THAN ONE FUNCTION\n",
    "tth_ranges = [[8.0, 16.3]] #limit around where you have your rings of interest \n",
    "eta_ranges = [[ -90, -5], [5, 90]]\n",
    "omega_ranges = [-180,  180]\n",
    "ds_ranges = []\n",
    "\n",
    "tth_gap = 0.5 # tolerances for ranges of evaluating gvectors\n",
    "ds_gap = 0.1 # tolerances for ranges of evaluating gvectors\n",
    "eta_gap = 1 # tolerances for ranges of evaluating gvectors\n",
    "\n",
    "dens_omg_tol = 1.0  #tolerance for creating density map \n",
    "dens_eta_tol = 1.1\n",
    "dens_tth_tol = 0.5  \n",
    "\n",
    "def set_GrainSpotter(path_gen, material,tth_ranges,eta_ranges,omega_ranges):\n",
    "    GS = experiment_settings.set_grainspotter(path_gen, material, domega=None)\n",
    "    GS.set_attr('tth_ranges'   , tth_ranges) # 12.7]])\n",
    "    GS.set_attr('ds_ranges'    , [] ) # [0.5, 1.0]]) # GV.ds_ranges)\n",
    "    GS.set_attr('eta_ranges'   , merge_overlaps( eta_ranges, margin=0, target=0)  ) # GV.eta_ranges)\n",
    "    GS.set_attr('omega_ranges' , [ omega_ranges]) # GV.omega_ranges)\n",
    "    GS.set_attr('cuts'         , [ 12, 0.6,  0.6] )\n",
    "    GS.set_attr('uncertainties', [0.5, 1.8,  1.5] ) # [sigma_tth sigma_eta sigma_omega] in degrees\n",
    "    GS.set_attr('nsigmas'      , 1)\n",
    "    GS.set_attr('eulerstep'    , 6)\n",
    "    GS.set_attr('Nhkls_in_indexing', None)\n",
    "    GS.set_attr('random', 10000)\n",
    "    GS.set_attr('positionfit', True)\n",
    "    return GS\n",
    "\n",
    "\n",
    "def set_PolySim(path_gen, grainspotter = None, material = None):\n",
    "    PS = experiment_settings.set_polyxsim(grainspotter, material)\n",
    "    PS.set_attr('inp_file', grainspotter.log_file.strip('.log'))\n",
    "    PS.set_attr('beamflux', 1e12)\n",
    "    PS.set_attr('beampol_factor', 1)\n",
    "    PS.set_attr('beampol_direct', 0)\n",
    "    PS.set_attr('stem'  , grainspotter.log_file.replace('.log', '_sim'))\n",
    "    PS.set_attr('grains', [])\n",
    "    PS.set_attr('omega_start', grainspotter.omega_ranges[0][0])\n",
    "    PS.set_attr('omega_step' , abs(grainspotter.domega))\n",
    "    PS.set_attr('omega_end'  , grainspotter.omega_ranges[-1][1])\n",
    "    PS.set_attr('theta_min'  , grainspotter.tth_ranges[0][0]/2)\n",
    "    PS.set_attr('theta_max'  , grainspotter.tth_ranges[-1][1]/2)\n",
    "    PS.set_attr('no_grains'  , 1)\n",
    "    PS.set_attr('gen_U'   , 0)\n",
    "    PS.set_attr('gen_pos' , [0, 0])\n",
    "    PS.set_attr('gen_eps' , [1, 0, 0 ,0, 0])\n",
    "    PS.set_attr('gen_size', [0.0, 0.0, 0.0 ,0.0])\n",
    "    PS.set_attr('make_image', 0)\n",
    "    PS.set_attr('output', ['.tif', '.par', '.gve'])\n",
    "    PS.set_attr('bg' , 0)\n",
    "    PS.set_attr('psf', 0.7)\n",
    "    PS.set_attr('peakshape', [1, 4, 0.5])\n",
    "    return PS\n",
    "\n",
    "\n",
    "def set_DATA(path_gen, i_load, i_slow, i_fast, detectors, material):\n",
    "    yml_det_order = [1] # [4,1,2,3]\n",
    "    DATA = pyTSXRD.DataAnalysis()\n",
    "    DATA.set_attr('material', material)\n",
    "    for det_num in detectors:\n",
    "        S = set_SweepProcessor(path_gen, i_load, i_slow, i_fast, det_num, material)\n",
    "        DATA.add_to_attr('sweepProcessors', S)\n",
    "    DATA.set_attr('yml_det_order', yml_det_order)\n",
    "    DATA.set_attr('directory'    , S.directory)\n",
    "    DATA.set_attr('name'         , f's{i_slow:03d}_f{i_fast:03d}_'+material['name'])\n",
    "    DATA.set_attr('position'     , S.position)\n",
    "    DATA.set_attr('rotation'     , [0,0,0])\n",
    "    DATA.set_attr('sample_pix_x',np.linspace(-3.5, 3.5, 701)) #sample size and pixels used when creating map\n",
    "    DATA.set_attr('sample_pix_y',np.linspace(-3.5, 3.5, 701))\n",
    "    DATA.set_attr('beamsize', 0.1) #beamsize in mm\n",
    "    if S.log_meta:\n",
    "        load_values = [ent['load'] for ent in S.log_meta['entries']]\n",
    "        DATA.set_attr('pressure', sum(load_values) / len(load_values))\n",
    "    return DATA\n",
    "\n",
    "def set_paths(path_gen, load_states, slow_translations, fast_translations, detectors, material):\n",
    "    list_DATApaths = []\n",
    "    GE_list = []\n",
    "    for i_load in load_states[:]: # \n",
    "        for i_slow in slow_translations[:]:     # (e.g. idty1).\n",
    "            for i_fast in fast_translations[:]: # (e.g. idtz2).\n",
    "                DATA = set_DATA(path_gen, i_load, i_slow, i_fast, detectors, material)\n",
    "                DATA = pickle.load(open(DATA.directory + DATA.name + \"_DATA.p\",\"rb\") )\n",
    "                for g in DATA.gvectorEvaluator.gvectors:\n",
    "                    g['stage_x'], g['stage_y'], g['stage_z'] = DATA.position\n",
    "                pickle.dump(DATA, open(DATA.directory+DATA.name+\"_DATA.p\",\"wb\") )\n",
    "                list_DATApaths.append(DATA.directory+DATA.name+\"_DATA.p\")\n",
    "                GE_list.append(DATA.gvectorEvaluator)    \n",
    "    return list_DATApaths, GE_list\n",
    "\n",
    "load_states = [0] # Indices of loads to analyze\n",
    "slow_translations = [0]            # Indices of positions to analyze\n",
    "fast_translations = list(range(73)) # Indices of positions to analyze\n",
    "detectors         = [4]\n",
    "\n",
    "### HERE WE SET TTH-DEPENDENT THRESHOLD\n",
    "def parab_eq(a, x):\n",
    "    return a[0]*x*x + a[1]*x + a[2]\n",
    "def func(a):\n",
    "    datapoints = [( 5, 800), (11, 600), (15, 300)]  # 800 cts at 5 degrees, 600 at 11, and 300 at 15\n",
    "    return [parab_eq(a,x) - y for x,y in datapoints]\n",
    "a = fsolve(func, [1, 1, 1])\n",
    "def thr(tth):\n",
    "    return parab_eq(a, tth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959a0b3-9b30-4109-9161-de8f29761206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"TEST FOR CENTER ROTATION. LOADING RAW DATA. PEAKSERCHING, MERGING, APPLYING INSTRUMENT CONFIGURATION.\"\"\"\n",
    "# Test for the middle point to see if parameters are good. Here we print and plot and if we have a good sample we should see at least one grain\n",
    "slow_mid = len(slow_translations)//2 \n",
    "fast_mid = len(fast_translations)//2\n",
    "for i_load in load_states[0:1]: # \n",
    "    for i_slow in slow_translations[slow_mid:slow_mid+1]:     # (e.g. idty1).\n",
    "        for i_fast in fast_translations[fast_mid:fast_mid+1]: # (e.g. idtz2).\n",
    "            print(double_separator + f'\\nLOAD = {i_load}, TRANSLATIONS: slow = {i_slow}, fast = {i_fast}')\n",
    "            DATA = set_DATA(path_gen, i_load, i_slow, i_fast, detectors, material)  \n",
    "            DATA.process_images(frames = 'all', save_tifs = False, q0_pos = 'auto', rad_ranges = 'auto', thr = 'auto') #load and process images\n",
    "            DATA.peaksearch(peaksearch_thrs = 'auto', peakmerge_thrs = 'auto', min_peak_dist = 10) #search for peaks \n",
    "            DATA.index(thr = thr) #index peaks \n",
    "            DATA.gvectorEvaluator.remove_not_ranges(ds_ranges = [], tth_ranges=tth_ranges, omega_ranges=[omega_ranges], eta_ranges=eta_ranges) #only concider good rings\n",
    "            ds_tol = DATA.gvectorEvaluator.merged[0].peakIndexer.geometry.ds_from_tth(0.12)\n",
    "            DATA.evaluateGvectors(ds_tol=ds_tol, tth_gap=tth_gap, ds_gap=ds_gap, eta_gap=eta_gap) # these params only for calculating tth and eta ranges\n",
    "            DATA.searchGrains(grainSpotter = set_GrainSpotter(path_gen, material,tth_ranges,eta_ranges,omega_ranges)) #find grains \n",
    "            DATA.runPolyXSim(polyxsim = set_PolySim(path_gen, DATA.grainSpotter, material),GE_SIM_list=[DATA.gvectorEvaluator.merged[0]],also_plot=True)\n",
    "            pickle.dump(DATA, open(DATA.directory+DATA.name+\"_DATA.p\",\"wb\") )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48083bd2-5560-48ee-a1b9-01b122a523b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"LOADING RAW DATA. PEAKSERCHING, MERGING, APPLYING INSTRUMENT CONFIGURATION.\"\"\"\n",
    "# For all points \n",
    "for i_load in load_states[0:1]: # \n",
    "    for i_slow in slow_translations[:]:     # (e.g. idty1).\n",
    "        for i_fast in fast_translations[:]: # (e.g. idtz2).\n",
    "            print(double_separator + f'\\nLOAD = {i_load}, TRANSLATIONS: slow = {i_slow}, fast = {i_fast}')\n",
    "            DATA = set_DATA(path_gen, i_load, i_slow, i_fast, detectors, material)            \n",
    "            DATA.process_images(frames = 'all', save_tifs = False, q0_pos = 'auto', rad_ranges = 'auto', thr = 'auto') #load and process images\n",
    "            DATA.peaksearch(peaksearch_thrs = 'auto', peakmerge_thrs = 'auto', min_peak_dist = 10) #search for peaks \n",
    "            DATA.index(thr = thr) #index peaks \n",
    "            DATA.gvectorEvaluator.remove_not_ranges(ds_ranges = [], tth_ranges=DATA.grainspotter['tth_ranges'], omega_ranges=DATA.grainspotter['omega_ranges'], eta_ranges=DATA.grainspotter['eta_ranges']) #only concider good rings\n",
    "            ds_tol = DATA.gvectorEvaluator.merged[0].peakIndexer.geometry.ds_from_tth(0.12)\n",
    "            DATA.evaluateGvectors(ds_tol=ds_tol, tth_gap=tth_gap, ds_gap=ds_gap, eta_gap=eta_gap) # these params only for calculating tth and eta ranges\n",
    "            #DATA.searchGrains(grainSpotter = set_GrainSpotter(path_gen, material)) #find grains \n",
    "            #DATA.runPolyXSim(polyxsim = set_PolySim(path_gen, DATA.grainSpotter, material),GE_SIM_list=[DATA.gvectorEvaluator.merged[0]])\n",
    "            pickle.dump(DATA, open(DATA.directory+DATA.name+\"_DATA.p\",\"wb\") )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2379cd7-212a-409d-94b3-180986d3f617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "list_DATApaths, GE_list = set_paths(path_gen, load_states, slow_translations, fast_translations, detectors, material)\n",
    "ind_mid = int(len(list_DATApaths)/2)\n",
    "DATA  = copy.deepcopy(pickle.load(open(list_DATApaths[ind_mid], \"rb\")))\n",
    "DATA.set_attr('directory', DATA.directory.replace(DATA.directory.split('/')[-2]+'/', '') )\n",
    "DATA.set_attr('name', 's000_all_filtered')\n",
    "DATA.set_attr('sample_pix_x',np.linspace(-3.5, 3.5, 701)) #sample size and pixels used when creating map\n",
    "DATA.set_attr('sample_pix_y',np.linspace(-3.5, 3.5, 701))\n",
    "DATA.set_attr('beamsize', 0.1) \n",
    "DATA.set_attr('plot_range' ,[50,150,250,350,450,550,650])\n",
    "DATA.set_attr('label_range',[-3,-2,-1,0,1,2,3])\n",
    "#Merge data and remove peaks outside of ranges\n",
    "DATA_ALL = merge_DATA_list(DATA, list_DATApaths, spot3d_id_reg = 5000000)\n",
    "DATA_ALL.print()\n",
    "DATA_ALL.gvectorEvaluator.calc_histo(omega_pixsize=0.5,eta_pixsize=0.5,ds_eta_omega_file = None,plot=False,save_arrays = False)\n",
    "#Calc. sinogram \n",
    "#sinogram, pos_linspace, omg_linspace, eta_linspace = compute_sinogram('test', list_DATApaths, pos_step =0.1, omg_step = 0.25, eta_step = 0.1,\n",
    "                                     \t#ds_ranges = 'auto', tth_ranges = tth_ranges,omega_ranges = [omega_ranges],eta_ranges = eta_ranges,save_sinogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef210d4e-259a-4a8a-9d44-6233b38efecd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"SEACHING FOR GRAINS\"\"\"\n",
    "#Runs commands several times, removes used vectors. Can find more grains but slow\n",
    "g_list = []\n",
    "list_g_lists = []\n",
    "gve_list = copy.copy(DATA_ALL.gvectorEvaluator.gvectors)\n",
    "spot3d_id_to_remove = []\n",
    "\n",
    " # tolerances for grouping gvectors\n",
    "group_y_tol = 0.5\n",
    "group_tth_tol = 0.5 \n",
    "group_eta_tol = 0.18 \n",
    "group_omega_tol = 1.5\n",
    "\n",
    "\n",
    "for itr in range(16):\n",
    "    print(double_separator)\n",
    "    print('Iteration: ',itr)\n",
    "    print(double_separator)\n",
    "    GE_SIM_list = []\n",
    "    for GE in DATA_ALL.gvectorEvaluator.merged:\n",
    "        GE_SIM_list += GE.merged\n",
    "    DATA_ALL.set_attr('grains', [])\n",
    "    DATA_ALL.gvectorEvaluator.set_attr('gvectors', [gve for gve in gve_list if gve['spot3d_id'] not in spot3d_id_to_remove])\n",
    "    DATA_ALL.gvectorEvaluator.group_gvectors(group_y_tol=group_y_tol, group_tth_tol=group_tth_tol, group_eta_tol=group_eta_tol, group_omega_tol=group_omega_tol)\n",
    "    DATA_ALL.evaluateGvectors(ds_tol='auto', tth_gap=tth_gap, ds_gap=ds_gap, eta_gap=eta_gap)\n",
    "    DATA_ALL.searchGrains(grainSpotter = set_GrainSpotter(path_gen, material,tth_ranges,eta_ranges,omega_ranges))\n",
    "    DATA_ALL.runPolyXSim(polyxsim = set_PolySim(path_gen, DATA_ALL.grainSpotter, material), GE_SIM_list = [DATA_ALL.gvectorEvaluator.merged[ind_mid].merged[0]])\n",
    "    for g in DATA_ALL.grains:\n",
    "        g.compute_density_map(GE_SIM_list, DATA_ALL.sample_pix_x, DATA_ALL.sample_pix_y, DATA_ALL.beamsize, \n",
    "                              dens_omg_tol, dens_eta_tol, dens_tth_tol, support_thr=12,final_map=False,bigbeam=False)\n",
    "    for g in DATA_ALL.grains:\n",
    "        for gvm in g.gvectors:\n",
    "            for gve in gve_list:\n",
    "                if gvm['stage_y'] == gve['stage_y']:\n",
    "                    if gvm['omega'] == gve['omega']:\n",
    "                        GE, p = DATA_ALL.gvectorEvaluator.trace_peak_by_spot3d_id(gve['spot3d_id'])\n",
    "                        if p['spot3d_id'] == gvm['spot3d_id']:\n",
    "                            spot3d_id_to_remove.append(gve['spot3d_id'])\n",
    "    g_list += [g for g in DATA_ALL.grains if len(g.gvectors) > 0]\n",
    "    list_g_lists += [DATA_ALL.grains]\n",
    "\n",
    "DATA_ALL.set_attr('grains', g_list)\n",
    "n_grains = len(DATA_ALL.grains)\n",
    "print('Number of grains:', n_grains)\n",
    "pickle.dump(DATA_ALL, open(DATA_ALL.directory+DATA_ALL.name+\"_DATA_ALL.p\",\"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9fbf8-b235-4710-ae8e-68b5b6e2eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOAD DATA IF NEEDED\"\"\"\n",
    "DATA_ALL = set_DATA(path_gen, 0, 0, 0, detectors, material)\n",
    "DATA_ALL.set_attr('name','s000_all_filtered')\n",
    "DATA_ALL.set_attr('directory', DATA_ALL.directory.replace(DATA_ALL.directory.split('/')[-2]+'/', '') )\n",
    "file = open(DATA_ALL.directory + DATA_ALL.name + \"_DATA_ALL.p\",\"rb\")\n",
    "DATA_ALL = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a68b9-225c-43a1-ba73-4d6b760b05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"REMOVE DUPLICATES\"\"\"\n",
    "n_grains = len(DATA_ALL.grains)\n",
    "print('Number of grains:', n_grains )\n",
    "DATA_ALL.remove_duplicates(ang_tol=.5, pos_tol=0.1) #If set too high it can reove too many grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7eaf0-e590-4d3f-a51d-2844ffd428c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"CREATE DENSITY MAP FOR ALL GRAINS FOUND IN THE PREVIOUS STEP\"\"\"\n",
    "GE_SIM_list = []\n",
    "n_grains = len(DATA_ALL.grains)\n",
    "for GE in DATA_ALL.gvectorEvaluator.merged:\n",
    "    GE_SIM_list += GE.merged\n",
    "for i,g in enumerate(DATA_ALL.grains):\n",
    "    g.compute_density_map(GE_SIM_list, DATA_ALL.sample_pix_x, DATA_ALL.sample_pix_y, DATA_ALL.beamsize, \n",
    "                          dens_omg_tol, dens_eta_tol, dens_tth_tol, support_thr=8,sample_rot=0,final_map=True,bigbeam=False)\n",
    "    print('Density maps %.2f%% done   ' %((i+1)/n_grains*100), end=\"\\r\")\n",
    "    \n",
    "pickle.dump(DATA_ALL, open(DATA_ALL.directory+DATA_ALL.name+\"_DATA_ALL.p\",\"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878515d-59c3-4faf-8399-4e4c0dc440b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LOAD DATA IF NEEDED\"\"\"\n",
    "DATA_ALL = set_DATA(path_gen, 0, 0, 0, detectors, material)\n",
    "DATA_ALL.set_attr('name','s000_all_filtered')\n",
    "DATA_ALL.set_attr('directory', DATA_ALL.directory.replace(DATA_ALL.directory.split('/')[-2]+'/', '') )\n",
    "file = open(DATA_ALL.directory + DATA_ALL.name + \"_DATA_ALL_5.p\",\"rb\")\n",
    "DATA_ALL = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92c6a9-1dc8-4702-9036-86a4b083d060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"PLOT DENSITY MAPS\"\"\"\n",
    "DATA_ALL.plot_dmap(DATA_ALL.sample_pix_x,DATA_ALL.sample_pix_y,grain_number=28,plot_type = 'simple',also_save=True,with_colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97426385-eac9-4690-b493-083e1247e85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"TAKES DENSITY MAP AND RETURNS A MATRIX FOR EACH GRAIN\"\"\" \n",
    "completeness_th=0.45 #th for masking of the density map \n",
    "DATA_ALL.make_grainmatrix(completeness_th=completeness_th,also_plot=False,save_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9370fe9-3462-4604-84d6-e971d2c5e683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"CORRECT FOR TILT OF SAMPLE\"\"\"\n",
    "mu = -0.09\n",
    "DATA_ALL.tilt_correction(ang_inc=mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be16641-17c6-4a54-aafc-50be4d8dcbb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Define values we need convert plot from pixel values to mm\"\"\"\n",
    "DATA_ALL.set_attr('plot_range' ,[50,150,250,350,450,550,650])\n",
    "DATA_ALL.set_attr('label_range',[-3,-2,-1,0,1,2,3])\n",
    "\n",
    "#REMOVE PARTS OF GRAINS OUTSIDE OF GRAINBOUNDARIES \n",
    "radius = 701/2\n",
    "DATA_ALL.apply_samplemask(radius,also_plot=False,plot_invers=False,save_invers=False)\n",
    "\n",
    "#TAKE THE MOST COMPLETE GRAIN IN EACH POINT WHERE GRAINS OVERLAPP. OPTION TO PLOT & SAVE\n",
    "grain_th = 100 #If a grain has a total number of pixels below the th, the grain will be remove\n",
    "DATA_ALL.map_sample(also_plot=False,grain_th=grain_th)\n",
    "\n",
    "#PLOT AS AN INVERSE POLEFIGURE MAP\n",
    "name_file = 'pd_1' #extension to file name of map\n",
    "DATA_ALL.plot_colors(name_file,plot_type='full',also_save=False,mark_grainnumber=False,mark_millers=False)\n",
    "\n",
    "pickle.dump(DATA_ALL, open(DATA_ALL.directory+DATA_ALL.name+\"_DATA_MAP.p\",\"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4fbcb3-a8de-453e-b705-bdd03005e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"SOME GRAINS MIGHT BE SPLIT INTO TWO OR MORE PARTS, HERE THEY CAN BE COMBINED\"\"\"\n",
    "ang_tol = 1.73 #threshold to still be concidered the same grain\n",
    "pos_tol = 15 #distance in pixel index of any part of the grain to still be concidered the same grain\n",
    "DATA_ALL.combine_duplicates(ang_tol, pos_tol)\n",
    "\n",
    "#PLOT AS AN INVERSE POLEFIGURE MAP\n",
    "name_file = 'pd_2' #extension to file name of map\n",
    "DATA_ALL.plot_colors(name_file,plot_type='full',also_save=True,mark_grainnumber=False,mark_millers=False)\n",
    "pickle.dump(DATA_ALL, open(DATA_ALL.directory+DATA_ALL.name+\"_DATA_MAP.p\",\"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26bfea-8b5d-40c1-b4ec-74cfcfb3b3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hexrdgui",
   "language": "python",
   "name": "hexrdgui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
